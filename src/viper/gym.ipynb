{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation: Box(-inf, inf, (8,), float32), action: Discrete(4)\n",
      "n_threads 1\n",
      "n_gpus 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-17 16:27:11,458\tINFO services.py:1272 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
      "2021-08-17 16:27:11,464\tWARNING services.py:1730 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 58970112 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import ray\n",
    "from algorithms.utils import Config, LogClient, LogServer\n",
    "from algorithms.algorithm import RL\n",
    "\n",
    "os.environ['RAY_OBJECT_STORE_ALLOW_SLOW_STORAGE']='1'\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "This section contains run args, separated from args for the RL algorithm and agents\n",
    "\"\"\"\n",
    "args = Config()\n",
    "#### computation\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "args.n_thread = 1\n",
    "args.parallel = False\n",
    "args.device = 'cpu'\n",
    "args.n_cpu = 1 # per agent, used only if parallel = True\n",
    "args.n_gpu = 0\n",
    "\n",
    "#### general\n",
    "args.debug = False\n",
    "args.test = False # if no training, only test\n",
    "args.profiling = False\n",
    "backend = 'tensorboard'\n",
    "\n",
    "#### algorithm and environment\n",
    "from algorithms.config.SAC import getArgs\n",
    "\n",
    "import gym\n",
    "from algorithms.envs.Wrapper import GymWrapper\n",
    "env_name = 'LunarLander-v2'\n",
    "\n",
    "args.name='jupyter-visualization'\n",
    "\n",
    "#### misc\n",
    "args.save_period=900 # in seconds\n",
    "args.log_period=int(20)\n",
    "args.seed = None\n",
    "args.test_interval = int(3e4)\n",
    "args.n_test = 10\n",
    "\n",
    "def env_fn():\n",
    "    return GymWrapper(env_name, 0, 1)\n",
    "\n",
    "agent_args = getArgs(8, 4)\n",
    "\n",
    "algo_args = Config()\n",
    "algo_args.replay_size=int(1e6)\n",
    "algo_args.max_ep_len=1000\n",
    "algo_args.n_step=int(1e8)\n",
    "#### checkpoint\n",
    "algo_args.init_checkpoint = 'checkpoints/SAC-Lunar_LunarLander-v2_SAC_16686/21538671_259.63662453068207.pt'\n",
    "algo_args.start_step = 0\n",
    "\n",
    "agent_args.gamma=0.99\n",
    "\n",
    "##########################\n",
    "\n",
    "env = env_fn()\n",
    "print(f\"observation: {env.env.observation_space}, action: {env.env.action_space}\")\n",
    "del env\n",
    "algo_args.env_fn = env_fn\n",
    "args.env_fn = env_fn\n",
    "\n",
    "algo_args.agent_args = agent_args\n",
    "p_args, q_args, pi_args = agent_args.p_args, agent_args.q_args, agent_args.pi_args\n",
    "if args.debug:\n",
    "    pi_args.update_interval = 1\n",
    "    q_args.update_interval = 1\n",
    "    algo_args.batch_size = 4\n",
    "    algo_args.max_ep_len=2\n",
    "    algo_args.replay_size=1\n",
    "    if not p_args is None:\n",
    "        p_args.model_buffer_size = 4\n",
    "    algo_args.n_warmup=1\n",
    "    algo_args.n_test=1\n",
    "if args.test:\n",
    "    algo_args.n_warmup = 0\n",
    "    algo_args.n_test = 10\n",
    "    algo_args.n_step = 1\n",
    "if args.profiling:\n",
    "    algo_args.batch_size=128\n",
    "    if algo_args.agent_args.p_args is None:\n",
    "        algo_args.n_step = 50\n",
    "    else:\n",
    "        algo_args.n_step = algo_args.batch_size + 10\n",
    "        algo_args.replay_size = 1000\n",
    "        algo_args.n_warmup = algo_args.batch_size\n",
    "    algo_args.n_test = 1\n",
    "    algo_args.max_ep_len = 20\n",
    "if args.seed is None:\n",
    "    args.seed = int(time.time()*1000)%65536\n",
    "\n",
    "agent_args.parallel = args.parallel\n",
    "args.name = f'{args.name}_{env_name}_{agent_args.agent.__name__}_{args.seed}'\n",
    "\n",
    "\n",
    "if not p_args is None:\n",
    "    print(f\"rollout reuse:{(p_args.refresh_interval/q_args.update_interval*algo_args.batch_size)/p_args.model_buffer_size}\")\n",
    "# each generated data will be used so many times\n",
    "\n",
    "import torch\n",
    "torch.set_num_threads(args.n_thread)\n",
    "print(f\"n_threads {torch.get_num_threads()}\")\n",
    "print(f\"n_gpus {torch.cuda.device_count()}\")\n",
    "\n",
    "ray.init(ignore_reinit_error = True, num_gpus=len(os.environ['CUDA_VISIBLE_DEVICES'].split(',')))\n",
    "backend = ''\n",
    "logger = LogServer.remote({'run_args':args, 'algo_args':algo_args}, backend = backend)\n",
    "logger = LogClient(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoints/SAC-Lunar_LunarLander-v2_SAC_16686/21538671_259.63662453068207.pt\n"
     ]
    }
   ],
   "source": [
    "rl = RL(logger = logger, run_args=args, **algo_args._toDict())\n",
    "agent = rl.agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupyter-visualization_LunarLander-v2_SAC_8696\n",
      "[269.40733965 257.99874458 271.34513462 254.21914198 275.60869609\n",
      " 287.46198793 246.10683478 230.09543459  13.50881856 267.62237039]\n",
      "10 episodes average accumulated reward: 237.33745031748003\n",
      "scaled reward 237.33745031748003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "237.33745031748003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rl.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy import random\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282.49943385798315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the gym environment\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(23)\n",
    "\n",
    "# Let's watch how an untrained agent moves around\n",
    "rewards = []\n",
    "state = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "for j in range(1000):\n",
    "    action = agent.act(state.reshape(1, -1))\n",
    "    #action = random.choice(range(4))\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    if isinstance(action, torch.Tensor):\n",
    "        action = action.numpy()[0]\n",
    "    state, reward, done, _ = env.step(action[0])\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        break \n",
    "print(sum(rewards))\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the gym environment\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(23)\n",
    "\n",
    "# Let's watch how an untrained agent moves around\n",
    "\n",
    "state = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "last = '0'\n",
    "for j in range(200):\n",
    "#     action = agent.act(state)\n",
    "    tmp = input()\n",
    "    if len(tmp) == 0:\n",
    "        tmp = last\n",
    "    else:\n",
    "        last = tmp\n",
    "    action = int(tmp)\n",
    "    img.set_data(env.render(mode='rgb_array')) \n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
